{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0e84e7-5996-48ca-999d-48922a729046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from scipy.special import expit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from regionmask import mask_geopandas\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cmocean.cm as cmo\n",
    "\n",
    "plt.rcParams[\"font.family\"] = [\"serif\", \"sans-serif\", \"monospace\"][2]\n",
    "\n",
    "bd = os.path.join(\"/hn01-home\", \"spet5107\") # depends on device\n",
    "os.chdir(bd)\n",
    "\n",
    "# settings\n",
    "k = 1\n",
    "wd = [\"/hazGAN2/projects/bayofbengal_era5\", \"hazGAN2/projects/poweruk_winter\"][k]\n",
    "std_string = [\"gumbel\", \"standardised\"][k]\n",
    "v1, v2, v3 = [(\"ws\", \"tp\", \"msl\"), (\"u10_gust\", \"v10_gust\", \"r30\")][k]\n",
    "\n",
    "# choose φ-level\n",
    "generated_suffix = [\"\", \"_trunc04\", \"_trunc04_old\"][0]\n",
    "\n",
    "with open(os.path.join(wd, \"config.yaml\"), \"r\") as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "\n",
    "regions = [\"East Midlands\", \"West Midlands\", \"South West England\", \"South Wales\"]\n",
    "region_of_interest = regions[0]\n",
    "\n",
    "season = config[\"sfunc\"]\n",
    "local_crs = config[\"local_crs\"]\n",
    "\n",
    "print(\"Using {} domain.\".format(config[\"domain\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5e935d-7407-47fd-901f-8b03f345bb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_size(width, fraction=1):\n",
    "    \"\"\" Set aesthetic figure dimensions to avoid scaling in latex.\n",
    "    https://tobiasraabe.github.io/post/matplotlib-for-publications/\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    width: float\n",
    "            Width in pts\n",
    "    fraction: float\n",
    "            Fraction of the width which you wish the figure to occupy\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fig_dim: tuple\n",
    "            Dimensions of figure in inches\n",
    "    \"\"\"\n",
    "    # Width of figure\n",
    "    fig_width_pt = width * fraction\n",
    "\n",
    "    # Convert from pt to inches\n",
    "    inches_per_pt = 1 / 72.27\n",
    "\n",
    "    # Golden ratio to set aesthetic figure height\n",
    "    golden_ratio = (5 ** 0.5 - 1) / 2\n",
    "\n",
    "    # Figure width in inches\n",
    "    fig_width_in = fig_width_pt * inches_per_pt\n",
    "    # Figure height in inches\n",
    "    fig_height_in = fig_width_in * golden_ratio\n",
    "\n",
    "    return fig_width_in, fig_height_in\n",
    "\n",
    "def laplace(uniform, mu=0, b=1):\n",
    "    \"\"\"uniform -> Laplace(mu, b) (quantile function)\"\"\"\n",
    "    maxval = np.max(uniform)\n",
    "    if maxval == 1:\n",
    "        warn(\"Values == 1 found, scaling by 1e-6\")\n",
    "        uniform *= 1 - 1e-6\n",
    "    if maxval > 1:\n",
    "        raise ValueError(f\"Some uniform > 1 ({maxval})\")\n",
    "    \n",
    "    return np.where(\n",
    "        uniform <= 0.5, \n",
    "        mu + b * np.log(2 * uniform),\n",
    "        mu - b * np.log(2 - 2 * uniform)\n",
    "        )\n",
    "\n",
    "\n",
    "def inv_laplace(x, mu=0, b=1):\n",
    "    \"\"\"Laplace(mu, b) -> uniform (CDF function).\"\"\"\n",
    "    return np.where(\n",
    "        x <= mu,\n",
    "        0.5 * np.exp((x - mu) / b),\n",
    "        1 - 0.5 * np.exp(-(x - mu) / b)\n",
    "    )\n",
    "\n",
    "\n",
    "def gumbel(uniform):\n",
    "    \"\"\"uniform -> Gumbel(0, 1)\"\"\"\n",
    "    maxval = np.max(uniform)\n",
    "    if maxval == 1:\n",
    "        print(\"Values == 1 found, scaling by 1e-6\")\n",
    "        uniform *= 1 - 1e-6\n",
    "    if maxval > 1:\n",
    "        raise ValueError(f\"Some uniform > 1 ({maxval})\")\n",
    "    return -np.log(-np.log(uniform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cb1ef2-5af5-40b6-9e3d-78bd0858eccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp_max = 10_000\n",
    "\n",
    "print(f\"Laplace max for {rp_max} return period: {laplace(1 - 1/rp_max)}\")\n",
    "print(f\"Gumbel max for {rp_max} return period: {gumbel(1 - 1/rp_max)}\")\n",
    "print(f\"Laplace min for {rp_max} return period: {laplace(1/rp_max)}\")\n",
    "print(f\"Gumbel min for {rp_max} return period: {gumbel(1/rp_max)}\")\n",
    "\n",
    "print(laplace(0.999) - laplace(0.99))\n",
    "print(gumbel(0.999) - gumbel(0.99))\n",
    "print(\"\\nSo laplace stretches the tails very slightly less.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8422b71f-e261-4c9c-8e83-e87360a62f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = xr.open_dataset(os.path.join(wd, \"results\", \"training\", \"data.nc\"))\n",
    "train[\"standardised\"] = ([\"time\", \"lat\", \"lon\", \"field\"], laplace(train[\"uniform\"]).data)\n",
    "\n",
    "print(train.sizes)\n",
    "\n",
    "gener = xr.open_dataset(os.path.join(wd, \"results\", f\"generated{generated_suffix}\", \"netcdf\", \"data.nc\"), engine=\"netcdf4\")\n",
    "gener.load() # do the expensive server load once\n",
    "\n",
    "print(gener.sizes)\n",
    "train[\"params\"].isel(field=0, param=0).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b7c665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def load_events(df) -> Tuple[gpd.GeoDataFrame, pd.Series, float]:\n",
    "    \"\"\"Load events data and metadata, return GeoDataFrame and event times.\"\"\"\n",
    "    df.columns = [col.replace(\".\", \"_\") for col in df.columns]\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df[\"lon\"], df[\"lat\"]), crs=\"EPSG:4326\")\n",
    "    gdf[\"lat\"] = gdf.geometry.y\n",
    "    gdf[\"lon\"] = gdf.geometry.x\n",
    "    gdf = gdf.sort_values([\"event\", \"lat\", \"lon\"]).reset_index(drop=True)\n",
    "    return gdf\n",
    "\n",
    "\n",
    "def create_parameters(\n",
    "        gdf:gpd.GeoDataFrame, h:int, w:int, fields:list\n",
    "        ) -> np.ndarray:\n",
    "    \"\"\"Create hxwx6xk parameter array for distribution parameters.\"\"\"\n",
    "    params = np.full((h, w, 6, len(fields)), np.nan, dtype=np.float32)\n",
    "    \n",
    "    prefixes = [\"thresh_\", \"scale_\", \"shape_\"]\n",
    "    suffixes = [\"\", \"_lower\", \"_upper\"]\n",
    "    param_map = {0: 3, 1: 0, 2: 0}  # suffix index to parameter offset\n",
    "    \n",
    "    for k, field in enumerate(fields):\n",
    "        for i, suffix in enumerate(suffixes):\n",
    "            for j, prefix in enumerate(prefixes):\n",
    "                col = f\"{prefix}{field}{suffix}\"\n",
    "                if col in gdf.columns:\n",
    "                    values = gdf[[col, \"lat\", \"lon\"]].groupby([\"lat\", \"lon\"]).mean()[col].values\n",
    "                    params[:, :, j + param_map[i], k] = values.reshape([h, w])\n",
    "    \n",
    "    return params\n",
    "\n",
    "fits = pd.read_parquet(os.path.join(wd, \"results\", \"processing\", \"fitted.parquet\"))\n",
    "fits.head()\n",
    "gdf = load_events(fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8b15dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38ae9f8",
   "metadata": {},
   "source": [
    "#### Why are all the parameters NA?\n",
    "\n",
    "Re-run with \n",
    "```bash\n",
    "snakemake --profile profiles/slurm projects/poweruk_winter/results/processing/fitted.parquet -n\n",
    "```\n",
    "\n",
    "Then run\n",
    "\n",
    "```python\n",
    "fits = pd.read_parquet(os.path.join(wd, \"results\", \"processing\", \"fitted.parquet\"))\n",
    "fits.head()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da8204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fits = pd.read_parquet(os.path.join(wd, \"results\", \"processing\", \"fitted.parquet\"))\n",
    "fits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb92672b-f303-4df8-a342-a14a4b4071aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_kws = {\"edgecolor\": 'dimgrey', \"linewidth\": 0.5, \"bins\": 50, \"density\": True}\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10, 3))\n",
    "\n",
    "i = 0\n",
    "\n",
    "domain_train = [\"standardised\", \"uniform\", \"anomaly\"][i] # check the other one\n",
    "domain_gener = [std_string, \"uniform\", \"anomaly\"][i]\n",
    "\n",
    "q = 0.0\n",
    "\n",
    "ax = axs[0]\n",
    "y0 = train.sel(field=v1)[domain_train].max(dim=[\"lat\", \"lon\"]).values.ravel()\n",
    "y1 = gener.sel(field=v1)[domain_gener].max(dim=[\"lat\", \"lon\"]).values.ravel()\n",
    "dy = (gener.sel(field=v1)[domain_gener].max(dim=[\"time\"]) - train.sel(field=v1)[domain_train].max(dim=[\"time\"])).mean().item()\n",
    "dy_max = (gener.sel(field=v1)[domain_gener].max(dim=[\"time\"]) - train.sel(field=v1)[domain_train].max(dim=[\"time\"])).max().item()\n",
    "threshold = np.quantile(y0, q)\n",
    "y0_tail = y0[y0 > threshold]\n",
    "y1_tail = y1[y1 > threshold]\n",
    "ax.hist(y1_tail, color=\"lightblue\", label=\"Generated\", **hist_kws);\n",
    "ax.hist(y0_tail, color=\"white\", alpha=0.6, label=\"Training\", **hist_kws);\n",
    "ax.set_xlabel(r\"Max $\\lambda u_{10}$ anomaly (ms$^{-1})$\")\n",
    "print(\"{} train max: {}, generated max: {}, avg. diff: {}, max. diff: {}\".format(v1, y0.max(), y1.max(), dy, dy_max))\n",
    "\n",
    "ax = axs[1]\n",
    "y0 = train.sel(field=v2)[domain_train].max(dim=[\"lat\", \"lon\"]).values.ravel()\n",
    "y1 = gener.sel(field=v2)[domain_gener].max(dim=[\"lat\", \"lon\"]).values.ravel()\n",
    "dy = (gener.sel(field=v2)[domain_gener].max(dim=[\"time\"]) - train.sel(field=v2)[domain_train].max(dim=[\"time\"])).mean().item()\n",
    "dy_max = (gener.sel(field=v2)[domain_gener].max(dim=[\"time\"]) - train.sel(field=v2)[domain_train].max(dim=[\"time\"])).max().item()\n",
    "threshold = np.quantile(y0, q)\n",
    "y0_tail = y0[y0 > threshold]\n",
    "y1_tail = y1[y1 > threshold]\n",
    "ax.hist(y1_tail, color=\"lightblue\", label=\"Generated\", **hist_kws);\n",
    "ax.hist(y0_tail, color=\"white\", alpha=0.6, label=\"Training\", **hist_kws);\n",
    "ax.set_xlabel(r\"Max $\\lambda v_{10}$ anomaly [ms$^{-1}$]\")\n",
    "print(\"{} train max: {}, generated max: {}, avg. diff: {}, max. diff: {}\".format(v2, y0.max(), y1.max(), dy, dy_max))\n",
    "\n",
    "ax = axs[2]\n",
    "y0 = train.sel(field=v3)[domain_train].mean(dim=[\"lat\", \"lon\"]).values.ravel()\n",
    "y1 = gener.sel(field=v3)[domain_gener].mean(dim=[\"lat\", \"lon\"]).values.ravel()\n",
    "dy = (gener.sel(field=v3)[domain_gener].max(dim=[\"time\"]) - train.sel(field=v3)[domain_train].max(dim=[\"time\"])).mean().item()\n",
    "dy_max = (gener.sel(field=v3)[domain_gener].max(dim=[\"time\"]) - train.sel(field=v3)[domain_train].max(dim=[\"time\"])).max().item()\n",
    "threshold = np.quantile(y0, q)\n",
    "y0_tail = y0[y0 > threshold]\n",
    "y1_tail = y1[y1 > threshold]\n",
    "ax.hist(y1_tail, color=\"lightblue\", label=\"Generated\", **hist_kws);\n",
    "ax.hist(y0_tail, color=\"white\", alpha=0.6, label=\"Training\", **hist_kws);\n",
    "ax.set_xlabel(r\"Mean $r^{30}$ anomaly [m]\")\n",
    "ax.legend(loc=\"center right\")\n",
    "print(\"{} train max: {}, generated max: {}, avg. diff: {}, max. diff: {}\".format(v3, y0.max(), y1.max(), dy, dy_max))\n",
    "\n",
    "for ax in axs:\n",
    "    ax.spines[['right', 'top']].set_visible(False)\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.label_outer()\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.suptitle(f\"Overall\")\n",
    "\n",
    "fig.savefig(os.path.join(\n",
    "    wd, \"results\", \"figures\", \"tail_hists.png\"), dpi=300, transparent=True, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23db7648-5042-420d-844f-09b419bbdf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp, view train only\n",
    "def format_p(p):\n",
    "    if isinstance(p, list):\n",
    "        return {\"lon\": p[0], \"lat\": p[1]}\n",
    "    else:\n",
    "        return p\n",
    "    \n",
    "p = [format_p(p) for p in config[\"points_of_interest\"].values()][1]\n",
    "hist_kws = {\"edgecolor\": 'dimgrey', \"linewidth\": 0.5, \"bins\": 50, \"density\": True}\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10, 3))\n",
    "\n",
    "i = 2\n",
    "\n",
    "domain_train = [\"standardised\", \"uniform\", \"anomaly\"][i] # check the other one\n",
    "domain_gener = [std_string, \"uniform\", \"anomaly\"][i]\n",
    "\n",
    "q = 0.0\n",
    "\n",
    "ax = axs[0]\n",
    "y0 = train.sel(field=v1)[domain_train].sel(**p, method=\"nearest\").values.ravel()\n",
    "y1 = gener.sel(field=v1)[domain_gener].sel(**p, method=\"nearest\").values.ravel()\n",
    "threshold = np.quantile(y0, q)\n",
    "y0_tail = y0[y0 > threshold]\n",
    "y1_tail = y1[y1 > threshold]\n",
    "ax.hist(y1_tail, color=\"lightblue\", label=\"Generated\", **hist_kws);\n",
    "ax.hist(y0_tail, color=\"white\", alpha=0.6, label=\"Training\", **hist_kws);\n",
    "ax.set_xlabel(r\"Max $\\lambda u_{10}$ anomaly (ms$^{-1})$\")\n",
    "print(\"{} train max: {}, generated max: {}, diff: \".format(v1, y0.max(), y1.max()), y1.max() - y0.max())\n",
    "\n",
    "ax = axs[1]\n",
    "y0 = train.sel(field=v2)[domain_train].sel(**p, method=\"nearest\").values.ravel()\n",
    "y1 = gener.sel(field=v2)[domain_gener].sel(**p, method=\"nearest\").values.ravel()\n",
    "threshold = np.quantile(y0, q)\n",
    "y0_tail = y0[y0 > threshold]\n",
    "y1_tail = y1[y1 > threshold]\n",
    "ax.hist(y1_tail, color=\"lightblue\", label=\"Generated\", **hist_kws);\n",
    "ax.hist(y0_tail, color=\"white\", alpha=0.6, label=\"Training\", **hist_kws);\n",
    "ax.set_xlabel(r\"Max $\\lambda v_{10}$ anomaly [ms$^{-1}$]\")\n",
    "print(\"{} train max: {}, generated max: {}, diff: \".format(v2, y0.max(), y1.max()), y1.max() - y0.max())\n",
    "\n",
    "ax = axs[2]\n",
    "y0 = train.sel(field=v3)[domain_train].sel(**p, method=\"nearest\").values.ravel()\n",
    "y1 = gener.sel(field=v3)[domain_gener].sel(**p, method=\"nearest\").values.ravel()\n",
    "threshold = np.quantile(y0, q)\n",
    "y0_tail = y0[y0 > threshold]\n",
    "y1_tail = y1[y1 > threshold]\n",
    "ax.hist(y1_tail, color=\"lightblue\", label=\"Generated\", **hist_kws);\n",
    "ax.hist(y0_tail, color=\"white\", alpha=0.6, label=\"Training\", **hist_kws);\n",
    "ax.set_xlabel(r\"Mean $r^{30}$ anomaly [m]\")\n",
    "ax.legend(loc=\"center right\")\n",
    "ax.set_title(f\"At point {p['lat']:.2f}N, {p['lon']:.2f}E\")\n",
    "print(\"{} train max: {}, generated max: {}, diff: \".format(v3, y0.max(), y1.max()), y1.max() - y0.max())\n",
    "\n",
    "for ax in axs:\n",
    "    ax.spines[['right', 'top']].set_visible(False)\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.label_outer()\n",
    "\n",
    "plt.tight_layout()\n",
    "# fig.suptitle(f\"Thresholding tail above {q*100:.0f}th quantile ({domain_train})\")\n",
    "\n",
    "fig.savefig(os.path.join(\n",
    "    wd, \"results\", \"figures\", \"tail_hist_marginal.png\"), dpi=300, transparent=True, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7dd700",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([field['two_tailed'] for field in config[\"fields\"].values()]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913c36b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp_max = 10_000\n",
    "p_max = 1 - 1/rp_max\n",
    "\n",
    "print(f\"Using p_max = {p_max} for {rp_max} return period\")\n",
    "\n",
    "\n",
    "os.chdir(os.path.join(bd, \"hazGAN2\", \"workflow\"))\n",
    "from importlib import reload\n",
    "import src.python.statistics as stats\n",
    "reload(stats)\n",
    "os.chdir(bd)\n",
    "\n",
    "# do the same as in process_generated.py\n",
    "train_x = train[\"anomaly\"].values\n",
    "theta  = train[\"params\"].values\n",
    "\n",
    "# transform images to original scale using invPIT\n",
    "distns = [field['distn'] for field in config[\"fields\"].values()]\n",
    "two_tailed =[field['two_tailed'] for field in config[\"fields\"].values()]\n",
    "\n",
    "if False:\n",
    "    # option to force one-tailed\n",
    "    two_tailed = [False, False, False]\n",
    "    theta = theta[..., :3, :]  # drop lower/upper if one-tailed\n",
    "\n",
    "test_u = p_max * np.ones_like(train_x)\n",
    "upper_bounds = stats.invPIT(test_u, train_x, theta=theta, distns=distns, two_tailed=two_tailed)\n",
    "\n",
    "# Heatmaps\n",
    "fig, axs = plt.subplots(1, 3, figsize=(9, 2))\n",
    "train_maxima = train.isel(field=0)[\"uniform\"].max(dim=[\"time\"]).values\n",
    "im = axs[0].imshow(train_maxima[::-1, :])\n",
    "plt.colorbar(im, ax=axs[0])\n",
    "print(f\"Train maxima uniform: {train_maxima.max()}\")\n",
    "train_maxima = train.isel(field=0)[\"anomaly\"].max(dim=[\"time\"]).values\n",
    "im = axs[1].imshow(upper_bounds[0, ::-1, :, 0])\n",
    "plt.colorbar(im, ax=axs[1])\n",
    "im = axs[2].imshow(train_maxima[::-1, :])\n",
    "plt.colorbar(im, ax=axs[2])\n",
    "\n",
    "# Scatter plot\n",
    "fig, ax = plt.subplots(figsize=(2, 2))\n",
    "ax.scatter(train_maxima.ravel(), upper_bounds[0, :, :, 0].ravel(), s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b9eaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "gener2 = gener.copy()\n",
    "new_gener = stats.invPIT(gener[\"uniform\"].values, train_x, theta=theta, distns=distns, two_tailed=two_tailed)\n",
    "gener2[\"anomaly\"] = ([\"time\", \"lat\", \"lon\", \"field\"], new_gener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fd0466-4d26-469f-8408-21da499c23d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp, view train only\n",
    "p0, p1 = [format_p(p) for p in config[\"points_of_interest\"].values()][1:3]\n",
    "n0, n1 = [name for name in config[\"points_of_interest\"].keys()][1:3]\n",
    "\n",
    "hist_kws = {\"edgecolor\": 'dimgrey', \"linewidth\": 0.5, \"bins\": 50, \"density\": True}\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(6, 2))\n",
    "\n",
    "\n",
    "j = 1\n",
    "k = v3\n",
    "\n",
    "domain_train = [\"standardised\", \"uniform\", \"anomaly\"][j] # check the other one\n",
    "domain_gener = [std_string, \"uniform\", \"anomaly\"][j]\n",
    "print(f\"Plotting in {domain_train} and {domain_gener} domains.\")\n",
    "\n",
    "ax = axs[0]\n",
    "y0 = train.sel(field=k)[domain_train].sel(**p0, method=\"nearest\").values.ravel()\n",
    "y1 = train.sel(field=k)[domain_train].sel(**p1, method=\"nearest\").values.ravel()\n",
    "ax.scatter(y0, y1, color='k', s=5)\n",
    "y0_min, y0_max = y0.min(), y0.max()\n",
    "y1_min, y1_max = y1.min(), y1.max()\n",
    "ax.set_title(f\"Train\\n({domain_train})\")\n",
    "\n",
    "ax = axs[1]\n",
    "y0 = gener.sel(field=k)[domain_gener].sel(**p0, method=\"nearest\").values.ravel()\n",
    "y1 = gener.sel(field=k)[domain_gener].sel(**p1, method=\"nearest\").values.ravel()\n",
    "ax.scatter(y0, y1, color='k', s=5)\n",
    "ax.set_title(f\"Generated\\n({domain_gener})\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.axhline(y1_min, color=\"red\", linestyle=\"dashed\")\n",
    "    ax.axhline(y1_max, color=\"red\", linestyle=\"dashed\")\n",
    "    ax.axvline(y0_min, color=\"red\", linestyle=\"dashed\")\n",
    "    ax.axvline(y0_max, color=\"red\", linestyle=\"dashed\")\n",
    "    ax.set_xlabel(n0.title())\n",
    "    ax.set_ylabel(n1.title())\n",
    "    ax.label_outer();\n",
    "\n",
    "    if domain_train == \"uniform\":\n",
    "        # ax.set_ylim(0, 1)\n",
    "        # ax.set_xlim(0, 1)\n",
    "        ax.set_xscale(\"logit\")\n",
    "        ax.set_yscale(\"logit\")\n",
    "    else:\n",
    "        pass\n",
    "        ax.set_ylim(min(y1_min, y0.min()), max(y1_max, y1.max()))\n",
    "\n",
    "outpath = os.path.join(wd, \"results\", \"figures\", f\"scatter_{k}{generated_suffix}.png\")\n",
    "fig.savefig(outpath, dpi=300, transparent=True, bbox_inches=\"tight\")\n",
    "\n",
    "print(\"Saved as {}\".format(outpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bf873a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hazGAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
