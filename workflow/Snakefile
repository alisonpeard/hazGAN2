import os
import yaml
import glob
import sys

# load device configuration
configfile: "config.yaml"
PROJECT = config["project"]
DEVICE  = config["device"]
INDIR   = config['setup'][DEVICE]['input']
WD      = os.path.join("projects", PROJECT)

# assert project directory exists
assert os.path.exists(WD), f"Project directory {WD} does not exist."

# set up project environment
os.environ["SNAKEMAKE_PROJECT"] = PROJECT

# set up directories on device
RESULTS_DIR    = os.path.join(WD, "results")
RESOURCES_DIR  = os.path.join(WD, "resources")
PROCESSING_DIR = os.path.join(RESULTS_DIR, "processing")
TRAINING_DIR   = os.path.join(RESULTS_DIR, "training")
GENERATED_DIR  = os.path.join(RESULTS_DIR, "generated")
FIGURE_DIR     = os.path.join(RESULTS_DIR, "figures")

# make parent directories
os.makedirs(RESULTS_DIR, exist_ok=True)

# make subdirectories (with .gitignore)
for newdir in [PROCESSING_DIR, TRAINING_DIR, GENERATED_DIR, FIGURE_DIR]:
    os.makedirs(newdir, exist_ok=True)
    with open(os.path.join(newdir, ".gitignore"), "w") as f:
        f.write("*")

# choose device-specific conda environments
GEOENV  = config['setup'][DEVICE]['geoenv']
RENV    = config['setup'][DEVICE]['renv']
GPUENV  = config['setup'][DEVICE]['gpuenv']
RSUBDIR = config['setup'][DEVICE]['rsubdir']

# load project-specific configuration
configfile: f"{WD}/config.yaml"

DATASET    = config["dataset"]
INDIR      = INDIR[DATASET]

YEAR0      = config["year0"]
YEARN      = config["yearn"]
FIELDS     = config["fields"]
RESOLUTION = config["resolution"]
LONGITUDE  = config["longitude"]
LATITUDE   = config["latitude"]
RFUNC      = config["rfunc"]
SFUNC      = config["sfunc"]
MTHRESH    = config["marginal_threshold"]
YEARS      = list(range(YEAR0, YEARN))
KIMG       = config["kimg"]
TIMECOL    = config['setup'][DEVICE]["timecol"]
RFUNCS     = config["rfuncs_dir"]
RFUNCS     = os.path.join(WD, RFUNCS) if RFUNCS else None

# load the dates to select / exclude
EXCLUDE = config.get("exclude", None)

# load rules
# NOTE: comment rule files out if you want to avoid reruns
include: "rules/get_data.smk"
include: "rules/process_data.smk"
include: "rules/train_stylegan.smk"
include: "rules/process_output.smk"
include: "rules/plot.smk"

# run full workflow (up to checkpoint)
rule all:
    """Complete full data processing sequence."""
    input:
        os.path.join(GENERATED_DIR, "netcdf", "data.nc"),
        os.path.join(GENERATED_DIR, "netcdf", "dependent.nc"),
        os.path.join(GENERATED_DIR, "netcdf", "independent.nc"),
        expand(
            os.path.join(FIGURE_DIR, "parameters", "{key}_upper.png"),
            key=list(FIELDS.keys())
        ),
        os.path.join(FIGURE_DIR, "samples"),
        os.path.join(FIGURE_DIR, "barcharts", "event_intensity.png"),
        os.path.join(FIGURE_DIR, "correlations_field"),
        os.path.join(FIGURE_DIR, "correlations_spatial"),
        os.path.join(FIGURE_DIR, "scatterplots")
