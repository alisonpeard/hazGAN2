# HazGAN2 readme
This repository contains a `snakemake` workflow to generate multivariate climate event sets using extreme value theory and generative adversarial networks.

The workflow has been made as modular as possible to facilitate modifications for new applications.

The theory of the workflow is described in [this paper](link.to.paper.com) and the rest of this readme describes how to get started with the workflow.

## Getting started

```bash
# clone the repository
git clone git@github.com:alisonpeard/hazGAN2.git
cd hazGAN2
```

It is better to run snakemake from a CPU node rather than the head node, head nodes are extremely slow for creating conda environments.
```bash
# login to a CPU node
srun -p Short --pty /bin/bash
```

To set up snakemake on your machine, enter the following in the terminal, replacing `conda` with `micromamba` or `mamba` if you prefer:
```bash
conda create -c conda-forge -c bioconda -n snakemake snakemake
conda activate snakemake
conda config --set channel_priority strict #Â snakemake complains otherwise
conda install -c conda-forge conda=24.7.1
python -m pip install snakemake-executor-plugin-slurm #Â snakemake >= 9.0.0, if using SLURM
```

### Running rules
To run a rule, navigate to the repository root, activate snakemake and run the rule. E.g., to 
run all the rules in `get_data.smk` locally:
```bash
cd hazGAN2
micromamba activate snakemake
snakemake --profile profiles/local/ get_all_data --use-conda --cores 2
```
or if using SLURM:
```bash
snakemake --profile profiles/cluster/ --executor slurm get_all_data --use-conda
```
#### Sample rules:
```bash
snakemake --profile profiles/local/ process_all_data --use-conda --cores 2
snakemake --profile profiles/local/ fit_marginals --use-conda --cores 2
```
> ðŸ’­ For Apple Silicon, the R package `r-extremes` is not available on the conda `osx-arm64` subdirectory, so installation must be manually set to the `osx-64` subdirectory. If running a rule that will install the R environment, prefix the command with `CONDA_SUBDIR=osx-64`, e.g.,
```bash
CONDA_SUBDIR=osx-64 snakemake --profile profiles/local/ fit_marginals --use-conda --cores 2
```

### Making reports and DAGs
and to output the DAG for a specific rule:
```bash
#Â without files
snakemake process_all_data --dag | dot -Tpdf > docs/process_all_data.pdf
snakemake process_all_data --dag | dot -Tsvg > docs/process_all_data.svg

#Â with files
snakemake process_all_data --filegraph | dot -Tpdf > docs/process_all_data.pdf
snakemake process_all_data --filegraph | dot -Tsvg > docs/process_all_data.svg

# report
snakemake process_all_data --report docs/process_all_data.html
```
## Modifications and extensions
#### Basic
To create a new project you need to make the following changes:
1. `config/config.yaml`: change `project` value
2. `config/projects/`: add a YAML file named `{myproject}.yaml` with the same structure as existing project YAMLs
3. `resources/params/`: use `resources/grids/era5.nc` to make `{myproject}.nc` in `resources/params/` with any spatial parameters for variable construction from raw ERA5 variables (see other param files for examples).

#### Advanced
The following files may also need to be modified, depending on the project requirements:
- Add new variable construction functions to
    - `workflow/scripts/era5_utils.py`
    - `config/projects/{myproject}.yaml`
- Add new temporal aggregation functions $h_{k|t}(x)$ to
    - `workflow/scripts/era5_utils.py`
    - `config/projects/{myproject}.yaml:hfunc`
- Add new deasonalization $s_{|t}(x)$ methods to
    - `worflow/r_utils/sfuncs.R`
    - `config/projects/{myproject}.yaml:sfunc`
- Add new risk functionals $r_{|ijk}(x)$ to
    - `workflow/r_utils/r)funcs.R`
    - `config/projects/{myproject}.yaml:rfunc`
- Add new distribution definitions to 
    - `workflow/r_utils/{distribution}.R`:
        - `cdf()`
        - `threshold_selector()`


## Further information
### Data input structure
If you don't have access to the SoGE filestore, you should set up the input data structure as follows:
```
input/
â””â”€â”€ {variable_long_name}/
 Â Â  â””â”€â”€ nc/
 Â Â  Â Â  â””â”€â”€ {variable_long_name}_{year}.nc
 ```
 and the output (`results`) folder has the following structure:
 ```bash
 :
 â”œâ”€â”€ results/
 â”‚   â”œâ”€â”€ .gitignore
 â”‚   â””â”€â”€ {projectname}/
 â”‚   Â Â   â”œâ”€â”€ processing/
 â”‚    Â Â  â”œâ”€â”€ training/
 â”‚   Â Â   â”œâ”€â”€ generated/
 â”‚   Â Â   â””â”€â”€ analysis/
 :
```

### Repository map
The full repository is structured as follows:
```
hazGAN2/
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ docs/
â”œâ”€â”€ profiles/
â”‚Â Â  â””â”€â”€ {device}/
â”‚Â Â    Â  â””â”€â”€ config.yaml
â”œâ”€â”€ config/
â”‚Â Â  â”œâ”€â”€ config.yaml
â”‚Â Â  â””â”€â”€ projects/
â”‚Â Â    Â  â””â”€â”€ {projectname}.yaml
â”œâ”€â”€ workflow/
â”‚Â Â  â”œâ”€â”€ Snakefile
â”‚Â Â  â”œâ”€â”€ environments/
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ {renvs}.yaml
â”‚Â Â  â”‚Â Â  â””â”€â”€ {pythonenvs}.yaml
â”‚Â Â  â”œâ”€â”€ rules/
â”‚Â Â  â”‚Â Â  â””â”€â”€ {rulename}.smk
â”‚Â Â  â”œâ”€â”€ scripts/
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ {scriptname}.py
â”‚Â Â  â”‚Â Â  â””â”€â”€ {scriptname}.R
â”‚Â Â  â”œâ”€â”€ py_utils/
â”‚Â Â  â”‚Â Â  â””â”€â”€ {module}.py
â”‚Â Â  â””â”€â”€ r_utils/
â”‚    Â Â  â””â”€â”€ {module}.R
â”œâ”€â”€ packages/
â”‚Â Â  â”œâ”€â”€ hazGAN/
â”‚   â”‚Â Â  â”œâ”€â”€ pyproject.toml
â”‚   â”‚Â Â  â””â”€â”€ src/
â”‚   â”‚Â Â      â””â”€â”€ *
â”‚   â””â”€â”€ styleGAN2-DA/
â”‚   Â Â   â”œâ”€â”€ pyproject.toml
â”‚   Â Â   â””â”€â”€ src/
â”‚   Â Â       â””â”€â”€ *
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ .gitignore
â”‚   â””â”€â”€ {projectname}/
â”‚   Â Â   â”œâ”€â”€ processing/
â”‚    Â Â  â”œâ”€â”€ training/
â”‚   Â Â   â”œâ”€â”€ generated/
â”‚   Â Â   â””â”€â”€ analysis/
â”œâ”€â”€ resources/
â”‚   â”œâ”€â”€ .gitignore
â”‚   â”œâ”€â”€ grids/
â”‚   â”‚Â Â  â””â”€â”€ era5.nc
â”‚   â””â”€â”€ params/
â”‚   Â Â   â””â”€â”€ {projectname}.nc
â”‚â”€â”€ sbatch_dump/
â”‚Â Â  â””â”€â”€ .gitignore
â””â”€â”€ logs/
 Â Â  â””â”€â”€ .gitignore
```

### Tasks
- [ ] Separate conda environments for each rule set
- [ ] Training on styleGAN2-DA (make very modular)
- [ ] Post-processing samples `process_samples.py`
- [ ] Visualisation rules
- [ ] Extra analysis code/rules
- [ ] Either add test set back in or full remove
- [ ] Unit tests
- [ ] Create fallback `params` file
- [ ] Run `get_data` rules locally for 2020 subset
    - [x] `bayofbengal`
    - [ ] `renewablesuk`
- [ ] Run `process_data` rules locally for 2020 subset
    - [ ] `bayofbengal`
    - [ ] `renewablesuk`